{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather.gov has a dynamic table produced after the HTML is loaded.  To extract that information, I installed selenium.\n",
    "# With selenium I can use Python to control the browser and extract the rendered HTML after the tables are generated.\n",
    "# (I tried first with requests-html, but didn't have luck... but that installation made the selenium installation easier because\n",
    "# it installed the required Chrome web driver as well)\n",
    "\n",
    "# Outputs to ../data/weather_gov/weather_gov_[startdatechunk]_[enddatechunk].csv\n",
    "\n",
    "#pip install requests-html\n",
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/weather_gov/weather_gov' # this will be followed by yyyymmdd-yyyymmdd.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = datetime.date(2018,1,1) # note that this NEEDS TO BE THE FIRST OF THE MONTH for my later chunk loop to function\n",
    "enddate = datetime.date(2025,4,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url will be like https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20180101&end=20180120&plot=\n",
    "url_pt1 = 'https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start='\n",
    "url_pt2 = '&end='\n",
    "url_pt3 = '&plot='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request half a month at a time\n",
    "# generate the urls\n",
    "\n",
    "urls = []\n",
    "year_month_part = []\n",
    "prev_year_month_part = [] # The report request for a month includes several hours from the last day of the previous month.  This should categorize those.\n",
    "expectedmon = []          # This is the array to compare to.  If the month is not the expected month, go with the previous_year_month instead.\n",
    "filenames = []\n",
    "\n",
    "requestdate = startdate\n",
    "\n",
    "while requestdate <= enddate :\n",
    "    first_of_month = requestdate\n",
    "    mid_of_month = first_of_month + datetime.timedelta(days=14)\n",
    "    second_half_of_month = first_of_month + datetime.timedelta(days=15)\n",
    "    last_of_month = first_of_month + relativedelta(months=1) - datetime.timedelta(days=1)\n",
    "\n",
    "    if mid_of_month > enddate :\n",
    "        mid_of_month = enddate\n",
    "\n",
    "    first_of_month = str(first_of_month).replace(\"-\", \"\")\n",
    "    mid_of_month = str(mid_of_month).replace(\"-\", \"\")\n",
    "    \n",
    "    url = url_pt1\n",
    "    url += first_of_month\n",
    "    url += url_pt2\n",
    "    url += mid_of_month\n",
    "    url += url_pt3\n",
    "\n",
    "    urls.append(url)\n",
    "    year_month_part.append(str(requestdate)[0:8])          # store the corresponding yyyy-mm- for later (I'll need it!)\n",
    "    prevmon = requestdate - relativedelta(months=1)\n",
    "    prev_year_month_part.append(str(prevmon)[0:8])\n",
    "    expectedmon.append(requestdate.month)\n",
    "    filenames.append(str(first_of_month) + '-' + str(mid_of_month))\n",
    "\n",
    "    if second_half_of_month < enddate :\n",
    "        if last_of_month > enddate :\n",
    "            last_of_month = enddate\n",
    "    \n",
    "        second_half_of_month = str(second_half_of_month).replace(\"-\", \"\")\n",
    "        last_of_month = str(last_of_month).replace(\"-\", \"\")\n",
    "        \n",
    "        url = url_pt1\n",
    "        url += second_half_of_month\n",
    "        url += url_pt2\n",
    "        url += last_of_month\n",
    "        url += url_pt3\n",
    "    \n",
    "        urls.append(url)\n",
    "        year_month_part.append(str(requestdate)[0:8])\n",
    "        prevmon = requestdate - relativedelta(months=1)\n",
    "        prev_year_month_part.append(str(prevmon)[0:8])\n",
    "        expectedmon.append(requestdate.month)\n",
    "        filenames.append(str(second_half_of_month) + '-' + str(last_of_month))\n",
    "    \n",
    "    requestdate += relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20180101&end=20180115&plot=\n",
      "2018-01-\n",
      "1\n",
      "2017-12-\n",
      "20180101-20180115\n",
      "https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20180116&end=20180131&plot=\n",
      "2018-01-\n",
      "1\n",
      "2017-12-\n",
      "20180116-20180131\n",
      "https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20180201&end=20180215&plot=\n",
      "2018-02-\n",
      "2\n",
      "2018-01-\n",
      "20180201-20180215\n",
      "https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20180216&end=20180228&plot=\n",
      "2018-02-\n",
      "2\n",
      "2018-01-\n",
      "20180216-20180228\n",
      "https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20180301&end=20180315&plot=\n",
      "2018-03-\n",
      "3\n",
      "2018-02-\n",
      "20180301-20180315\n",
      "https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20250401&end=20250411&plot=\n"
     ]
    }
   ],
   "source": [
    "for i in range(5) :\n",
    "    print(urls[i])\n",
    "    print(year_month_part[i])\n",
    "    print(expectedmon[i])\n",
    "    print(prev_year_month_part[i])\n",
    "    print(filenames[i])\n",
    "print(urls[len(urls)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, '29', '05:48', '05')\n",
      "(8, '19', '19:48', '19')\n",
      "(12, '09', '00:48', '00')\n",
      "(9, '01', '12:48', '12')\n"
     ]
    }
   ],
   "source": [
    "# process the dates from something like 'Dec 9, 7:48 pm' into dates and times like [2020-12-30] & 07:48\n",
    "\n",
    "def extract_dateparts(extract_from) :\n",
    "    match = re.search(r'([A-Z][a-z][a-z])\\s(\\d+), (\\d+:\\d+\\d+ .m)', extract_from)   # search for the 3-letter month (Aug), 9 and 7:48 pm\n",
    "    if match :\n",
    "        monthnum = datetime.datetime.strptime(str(match.group(1)), \"%b\").month\n",
    "        daypart = str(match.group(2))\n",
    "        if len(daypart) == 1 :\n",
    "            daypart = '0' + daypart\n",
    "        timepart = str(dt.strptime(match.group(3), '%I:%M %p').strftime('%H:%M'))\n",
    "        hourpart = timepart[0:2]\n",
    "        return monthpart, daypart, timepart, hourpart\n",
    "    else :\n",
    "        print('Missed a regex match in a row... look into this and try again')\n",
    "\n",
    "print(extract_dateparts('Apr 29, 5:48 am'))\n",
    "print(extract_dateparts('Aug 19, 7:48 pm'))\n",
    "print(extract_dateparts('Dec 9, 12:48 am'))\n",
    "print(extract_dateparts('Sep 1, 12:48 pm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing chunk 175 of 175: https://www.weather.gov/wrh/timeseries?site=KBNA&hours=500&units=english&chart=off&headers=on&obs=tabular&hourly=true&pview=standard&font=12&history=yes&start=20250401&end=20250411&plot=                  \n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# processing chunk X of Y: url\n",
    "x = 1\n",
    "y = len(urls)\n",
    "\n",
    "j = 0 # use for index for year_month_part and filenames\n",
    "\n",
    "for url in urls :\n",
    "    print(f\"\\rprocessing chunk {x} of {y}: {url}                  \", end=\"\")\n",
    "    x += 1\n",
    "    browser.get(url)\n",
    "    time.sleep(15)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    df = pd.DataFrame(columns = ['date','time','hr','temp','wind_direction','wind_speed','wind_gust','visibility_miles','weather','clouds','prcp_1_hr'])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    if 'Heat' in soup.find('table', attrs={'id' : 'OBS_DATA'}).find('tr').text : # if the heat index is in there, the columns get shifted.\n",
    "        heatshift = 1                                                                  # shift wind direction and everything after !\n",
    "    else :\n",
    "        heatshift = 0\n",
    "    if 'Chill' in soup.find('table', attrs={'id' : 'OBS_DATA'}).find('tr').text : # if the wind chill is in there, the columns get shifted.\n",
    "        chillshift = 1                                                                  # shift wind direction and everything after !\n",
    "    else :\n",
    "        chillshift = 0\n",
    "\n",
    "    if soup.find('table', attrs={'id' : 'OBS_DATA'}).find('tr').findAll('th')[7+chillshift+heatshift].text.strip() != 'Weather' :\n",
    "        print()\n",
    "        print('error.  \"Weather\" header is not where expected.  In url ' + url)         # check these later?\n",
    "        print()\n",
    "\n",
    "    for row in soup.find('table', attrs={'id' : 'OBS_DATA'}).find_all('tr') :\n",
    "        data = row.findAll('td')\n",
    "        if len(data) > 0 :\n",
    "            monthnum, daypart, timepart, hr = extract_dateparts(data[0].text)\t# break this down!\n",
    "            if monthnum == expectedmon[j] :\n",
    "                df.loc[i,'date'] = year_month_part[j] + daypart\n",
    "            else :\n",
    "                df.loc[i,'date'] = prev_year_month_part[j] + daypart\n",
    "            df.loc[i,'time'] = timepart\n",
    "            df.loc[i,'hr'] = hr\n",
    "            df.loc[i,'temp'] = data[1].text\n",
    "            df.loc[i,'wind_direction'] = data[4+heatshift+chillshift].text\n",
    "    \n",
    "            # wind speeds display as '7', '9', '10', '0', and can include gusts like '20G43'\n",
    "            wind_data = re.search(r'^(\\d+)\\D*(\\d*$)', data[5+chillshift+heatshift].text)\n",
    "    \n",
    "            if wind_data :\n",
    "                df.loc[i,'wind_speed'] = wind_data.group(1) \n",
    "                df.loc[i,'wind_gust'] = wind_data.group(2)\n",
    "            else :\n",
    "                df.loc[i,'wind_speed'] = '0' \n",
    "                df.loc[i,'wind_gust'] = '0'\n",
    "    \n",
    "            df.loc[i,'visibility_miles'] = data[6+chillshift+heatshift].text\n",
    "            df.loc[i,'weather'] = data[7+chillshift+heatshift].text\n",
    "            df.loc[i,'clouds'] = data[8+chillshift+heatshift].text\n",
    "            df.loc[i,'prcp_1_hr'] = data[12+chillshift+heatshift].text\n",
    "            i += 1\n",
    "        elif  i != 0 :\n",
    "            print('error.  Unexpected blank row (more than just first row).  In url ' + url)\n",
    "            print()\n",
    "    \n",
    "    df.to_csv(filepath + filenames[j] + '.csv', index=False)\n",
    "    j += 1\n",
    "\n",
    "print()\n",
    "print('done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
